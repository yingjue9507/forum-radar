import flet as ft
import requests
import json
import time
import re
import datetime
import urllib3
import traceback
import threading
from bs4 import BeautifulSoup

# ================= ğŸ”§ 0. å…¨å±€é…ç½® =================

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- API é…ç½® ---
# æ³¨æ„ï¼šå¦‚æœè¿™ä¸ªåŸŸåå¤±æ•ˆï¼Œè¯·åœ¨æ—¥å¿—ä¸­æŸ¥çœ‹æŠ¥é”™ï¼Œå¹¶æ›¿æ¢æ­¤å¤„ URL
FORUM_API_URL = "https://com1.j3roe3vnnk4e92-udhle6.work/com/record.html"
TARGET_URL = "https://160.124.142.10:50415/index.html"

# ä¼ªè£… Header
SEARCH_HEADERS = {
    "Host": "com1.j3roe3vnnk4e92-udhle6.work",
    "User-Agent": "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36",
    "Referer": "https://qnxyl.2ldkc1pdg6fx5arh.work/",
    "Origin": "https://qnxyl.2ldkc1pdg6fx5arh.work",
    "Accept": "*/*",
    "Accept-Language": "zh-CN,zh;q=0.9",
    "Sec-Fetch-Mode": "no-cors"
}

SCRAPE_HEADERS = {
    "Host": "160.124.142.10:50415",
    "User-Agent": "Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
    "Connection": "keep-alive"
}


# ================= ğŸ› ï¸ 1. è¾…åŠ©å‡½æ•° =================

def format_timestamp(ts):
    try:
        if not ts: return ""
        ts_int = int(ts)
        if ts_int > 10000000000: ts_int = ts_int / 1000
        dt = datetime.datetime.fromtimestamp(ts_int)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return str(ts)


# ================= ğŸŒ 2. æ ¸å¿ƒé€»è¾‘ (å¸¦æ—¥å¿—å›è°ƒ) =================

def fetch_json_infinite(keyword, page_num, search_type, log_callback):
    """
    æœç´¢è¯·æ±‚é€»è¾‘ï¼Œæ‰€æœ‰å…³é”®æ­¥éª¤éƒ½ä¼šè°ƒç”¨ log_callback è¾“å‡ºåˆ°ç•Œé¢
    """
    callback_name = f"jQuery{int(time.time() * 1000)}_{int(time.time() * 1000)}"
    clean_keyword = keyword.strip()

    log_callback(f"ğŸ“¡ å‘èµ·è¯·æ±‚: ç¬¬{page_num}é¡µ, è¯={clean_keyword}")

    params = {
        "callback": callback_name, "orderby": "plid", "id": "67",
        "key_word": "", "key_msg_word": "", "page": str(page_num)
    }
    if search_type == "user":
        params["key_word"] = clean_keyword
    else:
        params["key_msg_word"] = clean_keyword

    # åŠ¨æ€ User-Agent
    headers = SEARCH_HEADERS.copy()
    headers[
        "User-Agent"] = f"Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{110 + int(time.time()) % 10}.0.0.0 Mobile Safari/537.36"

    for attempt in range(3):
        try:
            # log_callback(f"â³ å°è¯•è¿æ¥ ({attempt+1}/3)... URL: {FORUM_API_URL[:25]}...")
            response = requests.get(FORUM_API_URL, headers=headers, params=params, timeout=12, verify=False)

            if response.status_code == 200:
                text = response.text
                # log_callback(f"ğŸ“¥ æ”¶åˆ°å“åº” ({len(text)} å­—èŠ‚)")

                # è§£ææ–¹æ¡ˆ 1: JSONP
                match = re.search(r'jQuery.*?\((\{.*\})\)', text, re.DOTALL)
                json_data = None
                if match:
                    json_data = json.loads(match.group(1))

                # è§£ææ–¹æ¡ˆ 2: çº¯ JSON
                if json_data is None:
                    try:
                        clean_text = text.strip()
                        if clean_text.startswith('(') and clean_text.endswith(')'):
                            clean_text = clean_text[1:-1]
                        json_data = json.loads(clean_text)
                    except:
                        pass

                if json_data:
                    res_list = json_data.get('data') or json_data.get('list') or json_data.get('result')
                    count = len(res_list) if res_list else 0
                    log_callback(f"âœ… è§£ææˆåŠŸ: è·å–åˆ° {count} æ¡æ•°æ®")
                    return res_list if res_list is not None else []
                else:
                    log_callback(f"âš ï¸ è§£æå¤±è´¥: è¿”å›å†…å®¹ä¸æ˜¯ JSON/JSONP\nå†…å®¹é¢„è§ˆ: {text[:50]}")
            else:
                log_callback(f"âŒ HTTP é”™è¯¯: {response.status_code}")

        except requests.exceptions.ConnectionError:
            log_callback(f"âŒ è¿æ¥å¤±è´¥: åŸŸåå¯èƒ½å·²å¤±æ•ˆæˆ–æ— ç½‘ç»œ")
        except requests.exceptions.Timeout:
            log_callback(f"âŒ è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            log_callback(f"âŒ æœªçŸ¥é”™è¯¯: {str(e)}")

        time.sleep(1)

    log_callback("âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
    return None


def fetch_and_parse_data():
    """é‡‡é›†é€»è¾‘"""
    all_data = []
    logs = []
    try:
        logs.append(f"æ­£åœ¨è¿æ¥ç›®æ ‡...")
        response = requests.get(TARGET_URL, headers=SCRAPE_HEADERS, verify=False, timeout=15)
        response.encoding = 'utf-8'
        if response.status_code != 200: return [], f"çŠ¶æ€ç : {response.status_code}"

        soup = BeautifulSoup(response.text, 'html.parser')
        all_lis = soup.find_all("li")
        logs.append(f"ğŸ” å‘ç° {len(all_lis)} è¡Œæ•°æ®")

        processed_hashes = set()
        for li in all_lis:
            text = li.get_text(strip=True)
            if not text: continue
            p_match = re.search(r'(\d+)\s*[æœŸ:ï¼š]', text)
            if not p_match: continue
            period = f"{p_match.group(1)}æœŸ"

            section_name = "å…¶ä»–ç‰ˆå—"
            try:
                parent_ul = li.find_parent("ul")
                if parent_ul:
                    prev = parent_ul.find_previous(class_=re.compile(r'(tit|head|caption|pb-tit|ptyx-tit)'))
                    if prev: section_name = prev.get_text(strip=True)
            except:
                pass

            content = ""
            c_match = re.search(r'(ã€.*?ã€‘)', text)
            if c_match:
                content = c_match.group(1)
            else:
                parts = re.split(r'[:ï¼š]', text, 1)
                if len(parts) > 1: content = parts[1].strip()

            status = "å‡†" if "å‡†" in text else ("é”™" if "é”™" in text else ("æ›´æ–°ä¸­" if "æ›´æ–°" in text else ""))
            row_hash = f"{section_name}_{period}_{content}"
            if row_hash in processed_hashes: continue
            processed_hashes.add(row_hash)
            all_data.append([section_name, period, content, status])
        logs.append(f"âœ… æˆåŠŸæå– {len(all_data)} æ¡")
    except Exception as e:
        return [], f"âŒ è§£æé”™è¯¯: {str(e)}"
    return all_data, "\n".join(logs)


# ================= ğŸ“± 3. ä¸»ç•Œé¢ APP =================

def main(page: ft.Page):
    try:
        page.title = "æƒ…æŠ¥é›·è¾¾ v10.4"
        page.theme_mode = ft.ThemeMode.LIGHT
        page.padding = 0
        page.bgcolor = "#f0f2f5"

        # æŒä¹…åŒ–æ•°æ®
        watchlist_data = []
        try:
            watchlist_data = page.client_storage.get("watchlist") or []
        except:
            watchlist_data = []

        seen_ids = set()
        current_search_id = [0]
        scrape_results_data = []

        # ================= UI ç»„ä»¶ =================

        # --- è°ƒè¯•æ—¥å¿—ç»„ä»¶ ---
        debug_switch = ft.Switch(label="æ˜¾ç¤ºè°ƒè¯•æ—¥å¿—", value=False)
        debug_log_view = ft.ListView(height=150, spacing=2, padding=5, auto_scroll=True)
        debug_container = ft.Container(
            content=debug_log_view,
            bgcolor="black",
            padding=5,
            border_radius=5,
            visible=False  # é»˜è®¤éšè—
        )

        def add_debug_log(msg):
            """å‘ç•Œé¢å†™å…¥æ—¥å¿—"""
            timestamp = datetime.datetime.now().strftime("%H:%M:%S")
            color = "white"
            if "âŒ" in msg:
                color = "red"
            elif "âœ…" in msg:
                color = "green"
            elif "âš ï¸" in msg:
                color = "yellow"

            debug_log_view.controls.append(
                ft.Text(f"[{timestamp}] {msg}", color=color, size=10, font_family="monospace")
            )
            # é™åˆ¶æ—¥å¿—é•¿åº¦é˜²æ­¢å¡é¡¿
            if len(debug_log_view.controls) > 100:
                debug_log_view.controls.pop(0)
            page.update()

        def toggle_debug(e):
            debug_container.visible = debug_switch.value
            page.update()

        debug_switch.on_change = toggle_debug

        # --- æœç´¢ç»„ä»¶ ---
        search_type_dropdown = ft.Dropdown(
            options=[ft.dropdown.Option("content", "æœå†…å®¹"), ft.dropdown.Option("user", "æœç”¨æˆ·")],
            value="content", width=110, height=45, content_padding=10, bgcolor="white", text_size=14, border_radius=8
        )
        search_keyword = ft.TextField(
            hint_text="è¾“å…¥å…³é”®è¯...", height=45, expand=True, content_padding=10, bgcolor="white", border_radius=8,
            on_submit=lambda e: trigger_search_thread(e)
        )
        btn_search = ft.ElevatedButton("å¼€å§‹æœç´¢", on_click=lambda e: trigger_search_thread(e),
                                       bgcolor=ft.Colors.BLUE_600, color="white", height=40, expand=True)

        search_list_view = ft.ListView(expand=True, spacing=8, padding=10)
        status_text = ft.Text("å‡†å¤‡å°±ç»ª", size=12, color="grey")
        result_count = ft.Text("", size=12, color="amber")
        progress_bar = ft.ProgressBar(visible=False, color="blue", bgcolor="#E0E0E0")

        # --- å…³æ³¨ç»„ä»¶ ---
        watchlist_col = ft.ListView(expand=True, spacing=10, padding=20)

        def render_watchlist(e=None):
            keyword = new_user_input.value.strip().lower()
            watchlist_col.controls.clear()
            found = 0
            for u in watchlist_data:
                if not keyword or keyword in u.lower():
                    found += 1
                    watchlist_col.controls.append(ft.Container(
                        content=ft.Row([
                            ft.Row([ft.Icon(ft.Icons.STAR, color="amber"), ft.Text(u, size=16, weight="bold")]),
                            ft.IconButton(ft.Icons.DELETE_OUTLINE, icon_color="red",
                                          on_click=lambda e, user=u: remove_user(user))
                        ], alignment="spaceBetween"),
                        padding=15, bgcolor="white", border_radius=8,
                        on_click=lambda e, user=u: jump_to_search(user)
                    ))
            if keyword and found == 0:
                watchlist_col.controls.append(ft.Text(f"æœªæ‰¾åˆ° '{new_user_input.value}'ï¼Œç‚¹å‡»å³ä¾§ + æ·»åŠ ", color="grey"))
            page.update()

        def add_user(e):
            name = new_user_input.value.strip()
            if name and name not in watchlist_data:
                watchlist_data.append(name)
                page.client_storage.set("watchlist", watchlist_data)
                page.show_snack_bar(ft.SnackBar(ft.Text(f"âœ… å·²å…³æ³¨: {name}")))
                new_user_input.value = ""
                render_watchlist()
            elif name in watchlist_data:
                page.show_snack_bar(ft.SnackBar(ft.Text("âš ï¸ å·²å­˜åœ¨")))

        def remove_user(name):
            if name in watchlist_data:
                watchlist_data.remove(name)
                page.client_storage.set("watchlist", watchlist_data)
                render_watchlist()

        def jump_to_search(name):
            nav_bar.selected_index = 0
            view_search.visible = True;
            view_watch.visible = False;
            view_scrape.visible = False
            search_type_dropdown.value = "user"
            search_keyword.value = name.strip()
            page.update()
            trigger_search_thread(manual_query=name.strip(), manual_type="user")

        new_user_input = ft.TextField(
            hint_text="è¾“å…¥æ˜µç§°ç­›é€‰/æ·»åŠ ", expand=True, height=45, content_padding=10, bgcolor="white", border_radius=8,
            on_change=render_watchlist
        )

        # --- é‡‡é›†ç»„ä»¶ ---
        scrape_status = ft.Text("å‡†å¤‡å°±ç»ª", color="grey", size=12)
        log_box = ft.ListView(height=80, spacing=2, padding=10, auto_scroll=True)
        data_table = ft.DataTable(
            columns=[ft.DataColumn(ft.Text("ç‰ˆå—")), ft.DataColumn(ft.Text("å†…å®¹")), ft.DataColumn(ft.Text("çŠ¶æ€")),
                     ft.DataColumn(ft.Text("åˆ "))], rows=[])
        copy_text_field = ft.TextField(label="ğŸ“ é‡‡é›†ç»“æœ", multiline=True, min_lines=5, max_lines=8, text_size=12,
                                       bgcolor="white")
        btn_scrape = ft.ElevatedButton("ä¸€é”®é‡‡é›†", on_click=lambda e: trigger_scrape_thread(e),
                                       bgcolor=ft.Colors.BLUE_600, color="white", expand=True)

        # ================= ğŸ§µ é€»è¾‘éƒ¨åˆ† =================

        def trigger_search_thread(e=None, manual_query=None, manual_type=None):
            if "åœæ­¢" in btn_search.text:
                current_search_id[0] += 1
                btn_search.text = "å¼€å§‹æœç´¢";
                btn_search.bgcolor = ft.Colors.BLUE_600
                progress_bar.visible = False;
                status_text.value = "ğŸ›‘ å·²åœæ­¢";
                status_text.color = "red"
                page.update()
                return

            keyword = manual_query if manual_query else search_keyword.value
            current_type = manual_type if manual_type else search_type_dropdown.value
            if not keyword:
                page.show_snack_bar(ft.SnackBar(ft.Text("âŒ è¯·è¾“å…¥å…³é”®è¯")))
                return

            btn_search.text = "åœæ­¢æœç´¢";
            btn_search.bgcolor = ft.Colors.ORANGE_600
            progress_bar.visible = True
            status_text.value = f"ğŸš€ åˆå§‹åŒ–..."
            status_text.color = "blue"

            # æ¸…ç©ºå¹¶åˆå§‹åŒ–
            search_list_view.controls.clear()
            seen_ids.clear()
            debug_log_view.controls.clear()  # æ¯æ¬¡æœç´¢æ¸…ç©ºæ—¥å¿—
            add_debug_log(f"--- æ–°æœç´¢ä»»åŠ¡: {keyword} ({current_type}) ---")

            # è‡ªåŠ¨å±•å¼€æ—¥å¿—ï¼ˆå¦‚æœæƒ³å¼ºåˆ¶å±•å¼€å–æ¶ˆæ³¨é‡Šä¸‹ä¸€è¡Œï¼‰
            # if not debug_switch.value: debug_switch.value = True; debug_container.visible = True

            page.update()

            t = threading.Thread(target=run_search_background, args=(keyword, current_type, current_search_id[0] + 1),
                                 daemon=True)
            current_search_id[0] += 1
            t.start()

        def run_search_background(keyword, current_search_type, my_session_id):
            total_loaded = 0
            current_page = 1
            empty_retry_count = 0

            try:
                while True:
                    if current_search_id[0] != my_session_id: return

                    status_text.value = f"ğŸ“¡ è¯·æ±‚ç¬¬ {current_page} é¡µ..."
                    page.update()

                    # ä¼ é€’æ—¥å¿—å›è°ƒå‡½æ•°
                    items_list = fetch_json_infinite(keyword, current_page, current_search_type, add_debug_log)

                    if items_list is None:
                        status_text.value = "âš ï¸ ç½‘ç»œé‡è¯•ä¸­..."
                        page.update()
                        time.sleep(1)
                        continue

                    if len(items_list) == 0:
                        empty_retry_count += 1
                        add_debug_log(f"âš ï¸ ç¬¬ {current_page} é¡µæ— æ•°æ® (ç©ºæ¬¡:{empty_retry_count})")
                        if empty_retry_count >= 2:
                            status_text.value = f"âœ… åŠ è½½å®Œæ¯•"
                            status_text.color = "green"
                            break
                        else:
                            current_page += 1
                            time.sleep(1)
                            continue
                    else:
                        empty_retry_count = 0

                    new_controls = []
                    for item in items_list:
                        rec_id = str(item.get('id') or '')
                        if rec_id in seen_ids: continue
                        seen_ids.add(rec_id)

                        user = item.get('nickname') or item.get('username') or 'æœªçŸ¥'
                        raw = item.get('saycontent') or item.get('content') or ''
                        clean = re.sub(r'<[^>]+>', '', str(raw)).strip()
                        ts = format_timestamp(item.get('saytime') or item.get('time'))
                        is_vip = user in watchlist_data

                        new_controls.append(ft.Container(
                            content=ft.Column([
                                ft.Row([
                                    ft.Row([ft.Icon(ft.Icons.VERIFIED if is_vip else ft.Icons.PERSON, size=16,
                                                    color="orange" if is_vip else "grey"),
                                            ft.Text(user, weight="bold", color="orange" if is_vip else "black"),
                                            ft.Text(f"#{rec_id}", size=10, color="grey")]),
                                    ft.Text(ts, size=11, color="grey")
                                ], alignment="spaceBetween"),
                                ft.Container(height=5), ft.Text(clean, size=14, selectable=True),
                            ]), padding=10, border_radius=8, bgcolor="yellow.50" if is_vip else "white",
                            border=ft.border.all(1, "orange" if is_vip else "transparent")
                        ))
                        total_loaded += 1

                    search_list_view.controls.extend(new_controls)
                    result_count.value = f"å·²æ‰¾åˆ°: {total_loaded} æ¡"
                    page.update()
                    current_page += 1

                    # å†·å´
                    for i in range(2, 0, -1):
                        if current_search_id[0] != my_session_id: return
                        time.sleep(1)

            except Exception as e:
                err = str(e)
                status_text.value = f"å‡ºé”™: {err[:10]}"
                add_debug_log(f"âŒ çº¿ç¨‹ä¸¥é‡å´©æºƒ: {traceback.format_exc()}")
            finally:
                if current_search_id[0] == my_session_id:
                    btn_search.text = "å¼€å§‹æœç´¢";
                    btn_search.bgcolor = ft.Colors.BLUE_600
                    progress_bar.visible = False;
                    status_text.value = f"âœ… å®Œæˆ: {total_loaded}æ¡";
                    status_text.color = "green"
                    page.update()

        # --- é‡‡é›†çº¿ç¨‹ ---
        def trigger_scrape_thread(e):
            if btn_scrape.disabled: return
            btn_scrape.disabled = True;
            btn_scrape.text = "æ­£åœ¨é‡‡é›†..."
            scrape_status.value = "ğŸš€ è¿æ¥ä¸­...";
            scrape_status.color = "blue"
            log_box.controls.clear();
            page.update()
            t = threading.Thread(target=run_scrape_background, daemon=True)
            t.start()

        def run_scrape_background():
            scrape_results_data.clear()
            data, log_str = fetch_and_parse_data()
            for line in log_str.split('\n'):
                if line: log_box.controls.append(ft.Text(line, size=10))
            page.update()
            if data:
                scrape_status.value = "âœ… æˆåŠŸ";
                scrape_status.color = "green"
                for row in data: scrape_results_data.append(row)
                update_scrape_ui()
            else:
                scrape_status.value = "âŒ å¤±è´¥";
                scrape_status.color = "red"
            btn_scrape.disabled = False;
            btn_scrape.text = "ä¸€é”®é‡‡é›†";
            page.update()

        def update_scrape_ui():
            ft_rows = []
            text_lines = []
            for row in scrape_results_data:
                color = ft.Colors.GREEN if "å‡†" in row[3] else (ft.Colors.RED if "é”™" in row[3] else ft.Colors.BLACK)
                ft_rows.append(ft.DataRow(cells=[
                    ft.DataCell(ft.Text(row[0], size=10)), ft.DataCell(ft.Text(row[2], size=12, width=150)),
                    ft.DataCell(ft.Text(row[3], size=12, color=color)),
                    ft.DataCell(ft.IconButton(ft.Icons.DELETE_OUTLINE, icon_color="red", icon_size=20,
                                              on_click=lambda e, r=row: delete_scrape_item(e, r)))
                ]))
                text_lines.append(f"[{row[0]}] {row[1]}: {row[2]} ({row[3]})")
            data_table.rows = ft_rows
            copy_text_field.value = "\n".join(text_lines) if text_lines else ""
            page.update()

        def delete_scrape_item(e, row_data):
            if row_data in scrape_results_data:
                scrape_results_data.remove(row_data);
                update_scrape_ui()

        # ================= å¸ƒå±€ =================

        view_search = ft.Column([
            ft.Container(content=ft.Column([
                ft.Text("ğŸ” æƒ…æŠ¥é›·è¾¾ v10.4", size=20, weight="bold", color="white"),
                ft.Container(height=5),
                ft.Row([search_type_dropdown, search_keyword], spacing=10),
                ft.Row([btn_search], spacing=10),
                # ğŸ”¥ æ–°å¢æ—¥å¿—å¼€å…³
                ft.Row([debug_switch], alignment="end"),
                # ğŸ”¥ æ–°å¢æ—¥å¿—å®¹å™¨
                debug_container,
                ft.Row([status_text, result_count], alignment="spaceBetween"),
                progress_bar
            ]), padding=15, bgcolor=ft.Colors.BLUE_800),
            ft.Container(content=search_list_view, expand=True, padding=5)
        ], spacing=0, expand=True, visible=True)

        view_watch = ft.Column([
            ft.Container(content=ft.Row([new_user_input,
                                         ft.IconButton(ft.Icons.ADD_CIRCLE, icon_color="blue", icon_size=45,
                                                       on_click=add_user)]), padding=20, bgcolor="white"),
            ft.Container(content=ft.Text("ç‚¹å‡»å¡ç‰‡å¯å¿«é€Ÿæœç´¢", size=12, color="grey"),
                         padding=ft.padding.only(left=20)),
            ft.Container(content=watchlist_col, expand=True)
        ], expand=True, visible=False)

        view_scrape = ft.Column([
            ft.Container(content=ft.Column(
                [ft.Text("ğŸ“Š é‡‡é›†ä¸æ•´ç†", size=20, weight="bold", color="white"), ft.Row([btn_scrape]), scrape_status]),
                         padding=15, bgcolor=ft.Colors.BLUE_800),
            ft.Container(content=log_box, height=80, border=ft.border.all(1, "#eee"), bgcolor="white"),
            ft.Container(content=copy_text_field, padding=5),
            ft.Container(content=ft.ListView([data_table], expand=True), expand=True, padding=5)
        ], expand=True, visible=False)

        def nav_change(e):
            idx = e.control.selected_index
            view_search.visible = (idx == 0);
            view_watch.visible = (idx == 1);
            view_scrape.visible = (idx == 2)
            if idx == 1: new_user_input.value = ""; render_watchlist()
            page.update()

        nav_bar = ft.NavigationBar(destinations=[
            ft.NavigationBarDestination(icon=ft.Icons.SEARCH, label="æœç´¢"),
            ft.NavigationBarDestination(icon=ft.Icons.STAR, label="å…³æ³¨"),
            ft.NavigationBarDestination(icon=ft.Icons.DATA_ARRAY, label="é‡‡é›†"),
        ], on_change=nav_change, bgcolor="white", elevation=10)

        page.add(ft.Column([view_search, view_watch, view_scrape], expand=True), nav_bar)

    except Exception as e:
        page.clean()
        page.add(ft.Text(f"âŒ å¯åŠ¨é”™è¯¯: {traceback.format_exc()}", color="red"))


if __name__ == "__main__":
    ft.app(target=main)
