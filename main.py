import flet as ft
import requests
import json
import time
import re
import datetime
import urllib3
import os
import csv
from bs4 import BeautifulSoup

# ================= ğŸ”§ 0. å…¨å±€é…ç½® =================

CSV_FILENAME = "Lotto_Monitor_Data.csv"
WATCHLIST_FILENAME = "radar_watchlist_v2.json"

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- 1. è®ºå›æœç´¢ API ---
FORUM_API_URL = "https://com1.j3roe3vnnk4e92-udhle6.work/com/record.html"

SEARCH_HEADERS = {
    "Host": "com1.j3roe3vnnk4e92-udhle6.work",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
    "Referer": "https://qnxyl.2ldkc1pdg6fx5arh.work/",
    "Origin": "https://qnxyl.2ldkc1pdg6fx5arh.work",
    "Accept": "*/*",
    "Sec-Ch-Ua": '"Chromium";v="143", "Not A(Brand";v="24"',
    "Sec-Ch-Ua-Mobile": "?0",
    "Sec-Ch-Ua-Platform": '"Windows"',
    "Accept-Language": "zh-CN,zh;q=0.9",
    "Sec-Fetch-Site": "cross-site",
    "Sec-Fetch-Mode": "no-cors",
    "Sec-Fetch-Dest": "script"
}

# --- 2. é‡‡é›†ç›®æ ‡é…ç½® ---
TARGET_URL = "https://160.124.142.10:50415/index.html"

SCRAPE_HEADERS = {
    "Host": "160.124.142.10:50415",
    "Sec-Ch-Ua": '"Chromium";v="143", "Not A(Brand";v="24"',
    "Sec-Ch-Ua-Mobile": "?0",
    "Sec-Ch-Ua-Platform": '"Windows"',
    "Accept-Language": "zh-CN,zh;q=0.9",
    "Upgrade-Insecure-Requests": "1",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
    "Sec-Fetch-Site": "same-origin",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Dest": "iframe",
    "Referer": "https://160.124.142.10:50415/",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive"
}


# ================= ğŸ› ï¸ 1. è¾…åŠ©å‡½æ•° =================

def format_timestamp(ts):
    try:
        if not ts: return ""
        ts_int = int(ts)
        if ts_int > 10000000000: ts_int = ts_int / 1000
        dt = datetime.datetime.fromtimestamp(ts_int)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return str(ts)


def get_period_number(period_str):
    try:
        match = re.search(r'(\d+)', str(period_str))
        return int(match.group(1)) if match else 0
    except:
        return 0


# ================= ğŸŒ 2. æ ¸å¿ƒé€»è¾‘æ¨¡å— =================

# --- 2.1 è®ºå›æœç´¢ ---
def fetch_json_infinite(keyword, page_num, search_type="content"):
    callback_name = f"jQuery{int(time.time() * 1000)}_{int(time.time() * 1000)}"
    params = {
        "callback": callback_name,
        "orderby": "plid",
        "id": "67",
        "key_word": "",
        "key_msg_word": "",
        "page": str(page_num)
    }

    if search_type == "user":
        params["key_word"] = keyword.strip()
    else:
        params["key_msg_word"] = keyword.strip()

    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.get(FORUM_API_URL, headers=SEARCH_HEADERS, params=params, timeout=10, verify=False)
            if response.status_code == 200:
                match = re.search(r'jQuery.*?\((\{.*\})\)', response.text, re.DOTALL)
                if match:
                    data = json.loads(match.group(1))
                    result_list = data.get('data') or data.get('list')
                    return result_list if result_list is not None else []
        except Exception as e:
            print(f"è¯·æ±‚å¼‚å¸¸ (Page {page_num}): {e}")
            time.sleep(1)
    return None


# --- 2.2 åè®®æŠ“å– ---
def fetch_and_parse_data():
    all_data = []
    logs = []
    try:
        logs.append(f"æ­£åœ¨è¿æ¥: {TARGET_URL} ...")
        response = requests.get(
            TARGET_URL, headers=SCRAPE_HEADERS, verify=False, timeout=15,
            proxies={"http": None, "https": None}
        )
        response.encoding = 'utf-8'
        logs.append(f"æœåŠ¡å™¨å“åº”: {response.status_code}")

        if response.status_code != 200:
            return [], "\n".join(logs) + f"\nâŒ çŠ¶æ€ç å¼‚å¸¸: {response.status_code}"

        soup = BeautifulSoup(response.text, 'html.parser')
        all_lis = soup.find_all("li")
        logs.append(f"ğŸ” é¡µé¢å…±å‘ç° {len(all_lis)} è¡Œæ•°æ®ï¼Œå¼€å§‹ç­›é€‰...")

        count_valid = 0
        processed_hashes = set()

        for li in all_lis:
            text = li.get_text(strip=True)
            if not text: continue

            p_match = re.search(r'(\d+)\s*[æœŸ:ï¼š]', text)
            if not p_match: continue

            period_num = p_match.group(1)
            period = f"{period_num}æœŸ"

            section_name = "å…¶ä»–ç‰ˆå—"
            try:
                parent_ul = li.find_parent("ul")
                if parent_ul:
                    prev = parent_ul.find_previous(class_=re.compile(r'(tit|head|caption|pb-tit|ptyx-tit)'))
                    if prev: section_name = prev.get_text(strip=True)
            except:
                pass

            if section_name == "å…¶ä»–ç‰ˆå—":
                try:
                    grand_parent = li.find_parent("div", class_="bg") or li.find_parent("div", class_="ptyx")
                    if grand_parent:
                        tit_div = grand_parent.find(class_=re.compile(r'tit|head'))
                        if tit_div: section_name = tit_div.get_text(strip=True)
                except:
                    pass

            content = ""
            c_match = re.search(r'(ã€.*?ã€‘)', text)
            if c_match:
                content = c_match.group(1)
            else:
                parts = re.split(r'[:ï¼š]', text, 1)
                if len(parts) > 1: content = parts[1].strip()

            status = ""
            if "å‡†" in text:
                status = "å‡†"
            elif "é”™" in text:
                status = "é”™"
            elif "æ›´æ–°" in text:
                status = "æ›´æ–°ä¸­"

            row_hash = f"{section_name}_{period}_{content}"
            if row_hash in processed_hashes: continue
            processed_hashes.add(row_hash)

            all_data.append([section_name, period, content, status])
            count_valid += 1

        logs.append(f"âœ… æˆåŠŸæå– {count_valid} æ¡è®°å½•")

    except Exception as e:
        return [], f"âŒ è§£æé”™è¯¯: {str(e)}"
    return all_data, "\n".join(logs)


# --- 2.3 CSV å­˜å‚¨ (åŸæœ‰é‡‡é›†ç”¨) ---
def merge_and_save_csv(new_data_list):
    data_map = {}
    if os.path.exists(CSV_FILENAME):
        try:
            with open(CSV_FILENAME, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                header = next(reader, None)
                if header:
                    for row in reader:
                        if len(row) >= 4:
                            key = f"{row[0]}_{row[1]}"
                            data_map[key] = row
        except:
            pass

    added = 0
    updated = 0
    now_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

    for item in new_data_list:
        sec_name, period, content, status = item[0], item[1], item[2], item[3]
        unique_key = f"{sec_name}_{period}"
        new_row = [sec_name, period, content, status, now_str]

        if unique_key in data_map:
            old_row = data_map[unique_key]
            if old_row[2] != content or old_row[3] != status:
                data_map[unique_key] = new_row
                updated += 1
        else:
            data_map[unique_key] = new_row
            added += 1

    final_rows = list(data_map.values())
    final_rows.sort(key=lambda x: (x[0], -get_period_number(x[1])))

    try:
        with open(CSV_FILENAME, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['ç‰ˆå—åç§°', 'æœŸæ•°', 'å†…å®¹', 'çŠ¶æ€', 'æ›´æ–°æ—¶é—´'])
            writer.writerows(final_rows)
        return True, f"æ–°å¢ {added} æ¡ï¼Œæ›´æ–° {updated} æ¡"
    except Exception as e:
        return False, f"ä¿å­˜å¤±è´¥: {str(e)}"


# --- 2.4 å…³æ³¨åˆ—è¡¨ ---
def load_watchlist():
    if os.path.exists(WATCHLIST_FILENAME):
        try:
            with open(WATCHLIST_FILENAME, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            pass
    return []


def save_watchlist(data):
    try:
        with open(WATCHLIST_FILENAME, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except:
        pass


# ================= ğŸ“± 3. ä¸»ç•Œé¢ APP =================

def main(page: ft.Page):
    page.title = "æƒ…æŠ¥é›·è¾¾ v9.3 (å¯¼å‡ºå¢å¼ºç‰ˆ)"
    page.theme_mode = ft.ThemeMode.LIGHT
    page.padding = 0

    watchlist_data = load_watchlist()
    seen_ids = set()
    current_search_id = [0]

    # ğŸŒŸ æ–°å¢ï¼šç”¨äºç¼“å­˜æœç´¢ç»“æœæ•°æ®ä»¥ä¾¿å¯¼å‡º
    search_results_data = []

    # ================= é¡µé¢ 1: æœç´¢ =================
    search_type_dropdown = ft.Dropdown(
        options=[ft.dropdown.Option("content", "æœå†…å®¹"), ft.dropdown.Option("user", "æœç”¨æˆ·")],
        value="content", width=100, height=40, content_padding=10, bgcolor="white", text_size=13
    )
    search_keyword = ft.TextField(hint_text="è¾“å…¥å…³é”®è¯", height=40, expand=True, content_padding=10, bgcolor="white")
    search_list_view = ft.ListView(expand=True, spacing=0, padding=10)
    status_text = ft.Text("å‡†å¤‡å°±ç»ª", size=12, color="white70")
    result_count = ft.Text("", size=12, color="amber")
    progress_bar = ft.ProgressBar(visible=False, color="amber", bgcolor="#263238")

    def run_search_logic(e=None):
        my_session_id = current_search_id[0] + 1
        current_search_id[0] = my_session_id

        keyword = search_keyword.value
        if not keyword:
            page.show_snack_bar(ft.SnackBar(ft.Text("âŒ è¯·è¾“å…¥å…³é”®è¯")))
            return

        btn_search.text = "åœæ­¢"
        btn_search.bgcolor = ft.Colors.RED_400
        btn_export.visible = False  # æœç´¢æ—¶éšè—å¯¼å‡ºæŒ‰é’®ï¼Œé˜²æ­¢æ•°æ®ä¸å®Œæ•´å¯¼å‡º

        search_list_view.controls.clear()
        seen_ids.clear()
        search_results_data.clear()  # æ¸…ç©ºæ—§æ•°æ®

        progress_bar.visible = True
        status_text.value = "ğŸ” æœç´¢ä¸­..."
        result_count.value = ""
        page.update()

        total_loaded = 0
        current_page = 1
        empty_retry_count = 0

        try:
            while True:
                if current_search_id[0] != my_session_id: return

                status_text.value = f"æ­£åœ¨åŠ è½½ç¬¬ {current_page} é¡µ..."
                page.update()

                items_list = fetch_json_infinite(keyword, current_page, search_type_dropdown.value)

                if items_list is None:
                    status_text.value = "âš ï¸ ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•..."
                    time.sleep(1)
                    continue

                if len(items_list) == 0:
                    empty_retry_count += 1
                    if empty_retry_count >= 2:
                        status_text.value = f"âœ… æ‰€æœ‰æ•°æ®åŠ è½½å®Œæ¯•"
                        break
                    else:
                        current_page += 1
                        time.sleep(1)
                        continue
                else:
                    empty_retry_count = 0

                for item in items_list:
                    rec_id = str(item.get('id') or '')
                    if rec_id in seen_ids: continue
                    seen_ids.add(rec_id)

                    user = item.get('nickname') or item.get('username') or 'æœªçŸ¥'
                    raw = item.get('saycontent') or item.get('content') or ''
                    clean = re.sub(r'<[^>]+>', '', str(raw)).strip()
                    ts = item.get('saytime') or item.get('time')
                    ts_fmt = format_timestamp(ts)
                    is_vip = user in watchlist_data

                    # ğŸŒŸ æ ¸å¿ƒï¼šå°†æ•°æ®å­˜å…¥ç¼“å­˜åˆ—è¡¨
                    search_results_data.append([rec_id, user, ts_fmt, clean])

                    card = ft.Container(
                        content=ft.Column([
                            ft.Row([
                                ft.Row([
                                    ft.Icon(ft.Icons.VERIFIED if is_vip else ft.Icons.PERSON, size=16,
                                            color="orange" if is_vip else "grey"),
                                    ft.Text(user, weight="bold", color="orange" if is_vip else "black"),
                                    ft.Text(f"#{rec_id}", size=10, color="grey")
                                ]),
                                ft.Text(ts_fmt, size=11, color="grey")
                            ], alignment="spaceBetween"),
                            ft.Container(height=5),
                            ft.Text(clean, size=14, selectable=True),
                        ]),
                        padding=10, border_radius=8, bgcolor="yellow.50" if is_vip else "white",
                        border=ft.border.all(1, "orange" if is_vip else "#eeeeee"),
                        margin=ft.margin.only(bottom=5)
                    )
                    search_list_view.controls.append(card)
                    total_loaded += 1

                result_count.value = f"å·²æ‰¾åˆ°: {total_loaded} æ¡ (ç¬¬ {current_page} é¡µ)"
                if total_loaded % 5 == 0: page.update()

                current_page += 1

                # é˜²å°å»¶è¿Ÿ
                status_text.value = f"â³ é˜²å°å†·å´ä¸­... (ç­‰å¾… 3 ç§’)"
                page.update()
                time.sleep(2)

        except Exception as e:
            status_text.value = f"Err: {e}"
            print(f"Error logic: {e}")
        finally:
            if current_search_id[0] == my_session_id:
                btn_search.text = "æœç´¢"
                btn_search.bgcolor = ft.Colors.BLUE_600
                progress_bar.visible = False
                status_text.value = f"âœ… å®Œæˆï¼Œå…±æŠ“å– {total_loaded} æ¡"

                # ğŸŒŸ æœç´¢å®Œæˆåï¼Œå¦‚æœæœ‰æ•°æ®ï¼Œæ˜¾ç¤ºå¯¼å‡ºæŒ‰é’®
                if len(search_results_data) > 0:
                    btn_export.visible = True
                    btn_export.text = f"å¯¼å‡ºCSV ({len(search_results_data)}æ¡)"

                page.update()

    def stop_search(e):
        current_search_id[0] += 1
        btn_search.text = "æœç´¢"
        btn_search.bgcolor = ft.Colors.BLUE_600
        progress_bar.visible = False
        status_text.value = "ğŸ›‘ å·²åœæ­¢"
        # å³ä½¿åœæ­¢ï¼Œå¦‚æœæœ‰å·²æŠ“å–çš„æ•°æ®ï¼Œä¹Ÿå…è®¸å¯¼å‡º
        if len(search_results_data) > 0:
            btn_export.visible = True
            btn_export.text = f"å¯¼å‡ºCSV ({len(search_results_data)}æ¡)"
        page.update()

    def start_search_click(e):
        if btn_search.text == "åœæ­¢":
            stop_search(e)
        else:
            run_search_logic(e)

    # ğŸŒŸ æ–°å¢ï¼šå¯¼å‡ºæœç´¢ç»“æœåˆ° CSV
    def export_search_data(e):
        if not search_results_data:
            page.show_snack_bar(ft.SnackBar(ft.Text("âŒ æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®")))
            return

        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"SearchResult_{timestamp}.csv"

        try:
            with open(filename, "w", newline="", encoding="utf-8-sig") as f:
                writer = csv.writer(f)
                writer.writerow(["ID", "ç”¨æˆ·", "æ—¶é—´", "å†…å®¹"])  # è¡¨å¤´
                writer.writerows(search_results_data)  # æ•°æ®å†…å®¹

            page.show_snack_bar(ft.SnackBar(ft.Text(f"âœ… å¯¼å‡ºæˆåŠŸ: {filename}"), bgcolor="green"))
        except Exception as ex:
            page.show_snack_bar(ft.SnackBar(ft.Text(f"âŒ å¯¼å‡ºå¤±è´¥: {str(ex)}"), bgcolor="red"))

    btn_search = ft.ElevatedButton("æœç´¢", on_click=start_search_click, bgcolor=ft.Colors.BLUE_600, color="white")

    # ğŸŒŸ æ–°å¢ï¼šå¯¼å‡ºæŒ‰é’®ï¼ˆåˆå§‹éšè—ï¼‰
    btn_export = ft.ElevatedButton("å¯¼å‡ºCSV", on_click=export_search_data, bgcolor=ft.Colors.GREEN_600, color="white",
                                   visible=False)

    view_search = ft.Container(
        content=ft.Column([
            ft.Container(
                content=ft.Column([
                    ft.Text("ğŸ” è®ºå›æƒ…æŠ¥é›·è¾¾", size=20, weight="bold", color="white"),
                    ft.Row([search_type_dropdown, search_keyword, btn_search, btn_export]),  # ğŸŒŸ å°†å¯¼å‡ºæŒ‰é’®åŠ å…¥å¸ƒå±€
                    ft.Row([status_text, result_count], alignment="spaceBetween"),
                    progress_bar
                ]),
                padding=15, bgcolor=ft.Colors.BLUE_800
            ),
            search_list_view
        ]),
        visible=True
    )

    # ================= é¡µé¢ 2: å…³æ³¨ç®¡ç† =================
    new_user_input = ft.TextField(hint_text="è¾“å…¥æ˜µç§°", expand=True, height=40)
    watchlist_col = ft.ListView(expand=True, spacing=10, padding=20)

    def render_watchlist():
        watchlist_col.controls.clear()
        for u in watchlist_data:
            watchlist_col.controls.append(
                ft.Container(
                    content=ft.Row([
                        ft.Row([ft.Icon(ft.Icons.STAR, color="amber"), ft.Text(u, size=16, weight="bold")]),
                        ft.IconButton(ft.Icons.DELETE_OUTLINE, icon_color="red",
                                      on_click=lambda e, user=u: remove_user(user))
                    ], alignment="spaceBetween"),
                    padding=15, bgcolor="white", border=ft.border.all(1, "#eee"), border_radius=8,
                    on_click=lambda e, user=u: jump_to_search(user)
                )
            )
        page.update()

    def jump_to_search(name):
        nav_bar.selected_index = 0
        view_search.visible = True
        view_watch.visible = False
        view_scrape.visible = False
        search_type_dropdown.value = "user"
        search_keyword.value = name.strip()
        page.update()
        run_search_logic()

    def add_user(e):
        name = new_user_input.value.strip()
        if name and name not in watchlist_data:
            watchlist_data.append(name)
            save_watchlist(watchlist_data)
            new_user_input.value = ""
            render_watchlist()

    def remove_user(name):
        if name in watchlist_data:
            watchlist_data.remove(name)
            save_watchlist(watchlist_data)
            render_watchlist()

    view_watch = ft.Container(
        content=ft.Column([
            ft.Container(content=ft.Row([new_user_input,
                                         ft.IconButton(ft.Icons.ADD_CIRCLE, icon_color="blue", icon_size=40,
                                                       on_click=add_user)]), padding=20),
            ft.Text("  ç‚¹å‡»å¡ç‰‡å¯å¿«é€Ÿæœç´¢", size=12, color="grey"),
            watchlist_col
        ]),
        visible=False
    )

    # ================= é¡µé¢ 3: å®‰å“åè®®é‡‡é›† =================
    scrape_status = ft.Text("å‡†å¤‡å°±ç»ª", color="grey")
    log_box = ft.ListView(height=100, spacing=2, padding=10, auto_scroll=True)

    data_table = ft.DataTable(
        columns=[
            ft.DataColumn(ft.Text("ç‰ˆå—")),
            ft.DataColumn(ft.Text("å†…å®¹")),
            ft.DataColumn(ft.Text("çŠ¶æ€")),
            ft.DataColumn(ft.Text("åˆ ")),
        ],
        rows=[],
        column_spacing=10,
        heading_row_color=ft.Colors.BLUE_50,
        data_row_min_height=40,
    )

    def add_log(msg, color="black"):
        log_box.controls.append(ft.Text(f"[{datetime.datetime.now().strftime('%H:%M')}] {msg}", color=color, size=12))
        page.update()

    def delete_row(sec_name, period):
        if not os.path.exists(CSV_FILENAME): return
        new_rows = []
        deleted = False
        try:
            with open(CSV_FILENAME, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                header = next(reader, None)
                for row in reader:
                    if len(row) >= 2 and row[0] == sec_name and row[1] == period:
                        deleted = True
                        continue
                    new_rows.append(row)

            if deleted:
                with open(CSV_FILENAME, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    if header: writer.writerow(header)
                    writer.writerows(new_rows)
                page.show_snack_bar(ft.SnackBar(ft.Text(f"ğŸ—‘ï¸ å·²åˆ é™¤ {period}"), duration=1000))
                load_table_data()
        except:
            pass

    def load_table_data():
        if not os.path.exists(CSV_FILENAME): return
        ft_rows = []
        try:
            with open(CSV_FILENAME, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                next(reader, None)
                for row in reader:
                    if len(row) >= 4:
                        color = ft.Colors.GREEN if "å‡†" in row[3] else (
                            ft.Colors.RED if "é”™" in row[3] else ft.Colors.BLACK)
                        ft_rows.append(ft.DataRow(cells=[
                            ft.DataCell(ft.Column([
                                ft.Text(row[0], size=10, weight="bold"),
                                ft.Text(row[1], size=10, color="grey")
                            ], alignment="center", spacing=0)),
                            ft.DataCell(ft.Text(row[2], size=12, width=120, no_wrap=False)),
                            ft.DataCell(ft.Text(row[3], size=12, color=color)),
                            ft.DataCell(ft.IconButton(ft.Icons.DELETE_OUTLINE, icon_color="red", icon_size=20,
                                                      on_click=lambda e, s=row[0], p=row[1]: delete_row(s, p))),
                        ]))
            data_table.rows = ft_rows
            page.update()
        except:
            pass

    def start_scrape(e):
        btn_scrape.disabled = True
        btn_scrape.text = "æŠ“å–ä¸­..."
        scrape_status.value = "ğŸš€ æ­£åœ¨è¯·æ±‚..."
        scrape_status.color = ft.Colors.BLUE
        log_box.controls.clear()
        page.update()

        data, log_str = fetch_and_parse_data()
        for line in log_str.split('\n'):
            if line: add_log(line, "grey")

        if data:
            success, msg = merge_and_save_csv(data)
            if success:
                scrape_status.value = "âœ… æˆåŠŸ"
                scrape_status.color = ft.Colors.GREEN
                add_log(msg, "green")
                load_table_data()
            else:
                scrape_status.value = "âŒ å¤±è´¥"
                add_log(msg, "red")
        else:
            scrape_status.value = "âŒ æ— æ•°æ®"
            scrape_status.color = ft.Colors.RED

        btn_scrape.disabled = False
        btn_scrape.text = "ä¸€é”®é‡‡é›†"
        page.update()

    load_table_data()
    btn_scrape = ft.ElevatedButton("ä¸€é”®é‡‡é›†", on_click=start_scrape, bgcolor=ft.Colors.BLUE_600, color="white",
                                   width=150)

    view_scrape = ft.Container(
        content=ft.Column([
            ft.Container(
                content=ft.Column([
                    ft.Text("ğŸ“Š é‡‡é›†ä¸å½’æ¡£ (v9.3)", size=20, weight="bold", color="white"),
                    ft.Text(f"Target: {TARGET_URL}", size=10, color="white70", no_wrap=True),
                ]),
                padding=15, bgcolor=ft.Colors.BLUE_800
            ),
            ft.Container(
                content=ft.Row([btn_scrape, scrape_status], alignment="spaceBetween"),
                padding=10
            ),
            ft.Container(
                content=log_box,
                height=100, border=ft.border.all(1, "#eee"), border_radius=5, margin=10
            ),
            ft.Container(
                content=ft.ListView(
                    controls=[
                        ft.Row([data_table], scroll=ft.ScrollMode.AUTO)
                    ],
                    expand=True, spacing=10
                ),
                expand=True, padding=5
            )
        ]),
        visible=False,
        expand=True
    )

    def nav_change(e):
        idx = e.control.selected_index
        view_search.visible = (idx == 0)
        view_watch.visible = (idx == 1)
        view_scrape.visible = (idx == 2)
        if idx == 1: render_watchlist()
        if idx == 2: load_table_data()
        page.update()

    nav_bar = ft.NavigationBar(
        destinations=[
            ft.NavigationBarDestination(icon=ft.Icons.SEARCH, label="æœç´¢"),
            ft.NavigationBarDestination(icon=ft.Icons.STAR, label="å…³æ³¨"),
            ft.NavigationBarDestination(icon=ft.Icons.DATA_ARRAY, label="é‡‡é›†"),
        ],
        on_change=nav_change
    )

    page.add(ft.Column([view_search, view_watch, view_scrape], expand=True), nav_bar)


if __name__ == "__main__":
    ft.app(target=main)
